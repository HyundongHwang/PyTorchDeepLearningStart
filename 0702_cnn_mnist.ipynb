{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "import myutil as mu\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import TensorDataset  # 텐서데이터셋\n",
                "from torch.utils.data import DataLoader  # 데이터로더\n",
                "from torch.utils.data import Dataset\n",
                "import matplotlib.pyplot as plt  # 맷플롯립사용\n",
                "import torchvision.datasets as dsets\n",
                "import torchvision.transforms as transforms\n",
                "from torch.utils.data import DataLoader\n",
                "import random\n",
                "from sklearn.datasets import load_digits\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - CNN으로 MNIST 분류하기 \n",
                "   - 이번 챕터에서는 CNN으로 MNIST를 분류해보겠습니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " 임의의 텐서를 만듭니다. 텐서의 크기는 1 × 1 × 28 × 28입니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "inputs = torch.Tensor(1, 1, 28, 28)\n",
                "mu.log(\"inputs\", inputs)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 합성곱층과 풀링 선언하기 \n",
                "   - 이제 첫번째 합성곱 층을 구현해봅시다. \n",
                "   - 1채널 짜리를 입력받아서 32채널을 뽑아내는데 커널 사이즈는 3이고 패딩은 1입니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=(1, 1))\n",
                "mu.log(\"conv1\", conv1)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 이제 두번째 합성곱 층을 구현해봅시다. \n",
                "   - 32채널 짜리를 입력받아서 64채널을 뽑아내는데 커널 사이즈는 3이고 패딩은 1입니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=(1, 1))\n",
                "mu.log(\"conv2\", conv2)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 이제 맥스풀링을 구현해봅시다. \n",
                "   - 정수 하나를 인자로 넣으면 커널 사이즈와 스트라이드가 둘 다 해당값으로 지정됩니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
                "mu.log(\"pool\", pool)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 구현체를 연결하여 모델 만들기 \n",
                "   - 지금까지는 선언만한 것이고 아직 이들을 연결시키지는 않았습니다. \n",
                "   - 이들을 연결시켜서 모델을 완성시켜보겠습니다. \n",
                "   - 우선 입력을 첫번째 합성곱층을 통과시키고 합성곱층을 통과시킨 후의 텐서의 크기를 보겠습니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "out = conv1(inputs)\n",
                "mu.log(\"out = conv1(inputs)\", out)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 32채널의 28너비 28높이의 텐서가 되었습니다. \n",
                " - 32가 나온 이유는 conv1의 out_channel로 32를 지정해주었기 때문입니다. \n",
                " - 또한, 28너비 28높이가 된 이유는 패딩을 1폭으로 하고 3 × 3 커널을 사용하면 크기가 보존되기 때문입니다. \n",
                " - 이제 이를 맥스풀링을 통과시키고 맥스풀링을 통과한 후의 텐서의 크기를 보겠습니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "out = pool(out)\n",
                "mu.log(\"out = pool(out)\", out)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 32채널의 14너비 14높이의 텐서가 되었습니다. \n",
                " - 이제 이를 다시 두번째 합성곱층에 통과시키고 통과한 후의 텐서의 크기를 보겠습니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "out = conv2(out)\n",
                "mu.log(\"out = conv2(out)\", out)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 64채널의 14너비 14높이의 텐서가 되었습니다. \n",
                " - 64가 나온 이유는 conv2의 out_channel로 64를 지정해주었기 때문입니다. \n",
                " - 또한, 14너비 14높이가 된 이유는 패딩을 1폭으로 하고 3 × 3 커널을 사용하면 크기가 보존되기 때문입니다. \n",
                " - 이제 이를 맥스풀링을 통과시키고 맥스풀링을 통과한 후의 텐서의 크기를 보겠습니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "out = pool(out)\n",
                "mu.log(\"out = pool(out)\", out)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 이제 이 텐서를 펼치는 작업을 할 겁니다. \n",
                " - 그런데 펼치기에 앞서 텐서의 n번째 차원을 접근하게 해주는 .size(n)에 대해서 배워보겠습니다. \n",
                " - 현재 out의 크기는 1 × 64 × 7 × 7입니다. \n",
                " - out의 첫번째 차원이 몇인지 출력해보겠습니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "mu.log(\"out.size(0)\", out.size(0))\n",
                "mu.log(\"out.size(1)\", out.size(1))\n",
                "mu.log(\"out.size(2)\", out.size(2))\n",
                "mu.log(\"out.size(3)\", out.size(3))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " 이제 이를 가지고 .view()를 사용하여 텐서를 펼치는 작업을 해보겠습니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "out = out.view(out.size(0), -1)\n",
                "mu.log(\"out = out.view(out.size(0), -1)\", out)\n",
                "mu.log(\"out.size(1)\", out.size(1))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 배치 차원을 제외하고 모두 하나의 차원으로 통합된 것을 볼 수 있습니다. \n",
                " - 이제 이에 대해서 전결합층(Fully-Connteced layer)를 통과시켜보겠습니다. \n",
                " - 출력층으로 10개의 뉴런을 배치하여 10개 차원의 텐서로 변환합니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "fc = nn.Linear(out.size(1), 10)\n",
                "mu.log(\"fc\", fc)\n",
                "out = fc(out)\n",
                "mu.log(\"out = fc(out)\", out)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " CNN으로 MNIST 분류하기 \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "# 랜덤 시드 고정\n",
                "torch.manual_seed(777)\n",
                "\n",
                "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
                "if device == 'cuda':\n",
                "    torch.cuda.manual_seed_all(777)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " 학습에 사용할 파라미터를 설정합니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "learning_rate = 0.001\n",
                "training_epochs = 15\n",
                "batch_size = 100\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " 데이터로더를 사용하여 데이터를 다루기 위해서 데이터셋을 정의해줍니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "mnist_train = dsets.MNIST(root='MNIST_data/',  # 다운로드 경로 지정\n",
                "                          train=True,  # True를 지정하면 훈련 데이터로 다운로드\n",
                "                          transform=transforms.ToTensor(),  # 텐서로 변환\n",
                "                          download=True)\n",
                "\n",
                "mu.log(\"mnist_train\", mnist_train)\n",
                "\n",
                "mnist_test = dsets.MNIST(root='MNIST_data/',  # 다운로드 경로 지정\n",
                "                         train=False,  # False를 지정하면 테스트 데이터로 다운로드\n",
                "                         transform=transforms.ToTensor(),  # 텐서로 변환\n",
                "                         download=True)\n",
                "\n",
                "mu.log(\"mnist_test\", mnist_test)\n",
                "\n",
                "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
                "                                          batch_size=batch_size,\n",
                "                                          shuffle=True,\n",
                "                                          drop_last=True)\n",
                "\n",
                "mu.log(\"len(data_loader)\", len(data_loader))\n",
                "mu.log(\"data_loader.sampler.num_samples\", data_loader.sampler.num_samples)\n",
                "mu.log(\"data_loader.batch_size\", data_loader.batch_size)\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " 이제 클래스로 모델을 설계합니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CNN(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "\n",
                "        # 첫번째층\n",
                "        # ImgIn shape=(?, 28, 28, 1)\n",
                "        #    Conv     -> (?, 28, 28, 32)\n",
                "        #    Pool     -> (?, 14, 14, 32)\n",
                "        self.layer1 = nn.Sequential(\n",
                "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=2, stride=1, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
                "        )\n",
                "\n",
                "        # 두번째층\n",
                "        # ImgIn shape=(?, 14, 14, 32)\n",
                "        #    Conv      ->(?, 14, 14, 64)\n",
                "        #    Pool      ->(?, 7, 7, 64)\n",
                "        self.layer2 = nn.Sequential(\n",
                "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=2, stride=1, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
                "        )\n",
                "\n",
                "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
                "        self.fc = nn.Linear(in_features=7 * 7 * 64, out_features=10, bias=True)\n",
                "\n",
                "        # 전결합층 한정으로 가중치 초기화\n",
                "        nn.init.xavier_normal_(self.fc.weight)\n",
                "\n",
                "    def forward(self, x):\n",
                "        out = self.layer1(x)\n",
                "        out = self.layer2(out)\n",
                "        # 전결합층을 위해서 Flatten\n",
                "        out = out.view(out.size(0), -1)\n",
                "        out = self.fc(out)\n",
                "        return out\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " 모델을 정의합니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = CNN().to(device)\n",
                "mu.log(\"model\", model)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " 비용 함수와 옵티마이저를 정의합니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "criterion = nn.CrossEntropyLoss().to(device)\n",
                "mu.log(\"criterion\", criterion)\n",
                "\n",
                "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
                "mu.log(\"optimizer\", optimizer)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " 총 배치의 수를 출력해보겠습니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "total_batch = len(data_loader)\n",
                "mu.log(\"total_batch\", total_batch)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 총 배치의 수는 600입니다. \n",
                " - 그런데 배치 크기를 100으로 했으므로 결국 훈련 데이터는 총 60,000개란 의미입니다. \n",
                " - 이제 모델을 훈련시켜보겠습니다. \n",
                " - (시간이 꽤 오래 걸립니다.) \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "mu.plt_init()\n",
                "\n",
                "for epoch in range(training_epochs + 1):\n",
                "    avg_cost = 0\n",
                "    hypothesis = None\n",
                "    Y = None\n",
                "\n",
                "    for X, Y in data_loader:\n",
                "        X = X.to(device)\n",
                "        Y = Y.to(device)\n",
                "\n",
                "        hypothesis = model(X)\n",
                "        cost = criterion(hypothesis, Y)\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        cost.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "        avg_cost += cost / total_batch\n",
                "\n",
                "    accuracy = mu.get_cross_entropy_accuracy(hypothesis, Y)\n",
                "    mu.log_epoch(epoch, training_epochs, avg_cost, accuracy)\n",
                "\n",
                "mu.plt_show()\n",
                "\n",
                "mu.log(\"model\", model)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                " - 이제 테스트를 해보겠습니다. \n",
                " -98%의 정확도를 얻습니다. 다음 챕터에서는 층을 더 쌓아보겠습니다. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
                "with torch.no_grad():\n",
                "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
                "    Y_test = mnist_test.test_labels.to(device)\n",
                "\n",
                "    prediction = model(X_test)\n",
                "    accuracy = mu.get_cross_entropy_accuracy(prediction, Y)\n",
                "    mu.log(\"accuracy\", accuracy)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 2
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython2",
            "version": "2.7.17"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}